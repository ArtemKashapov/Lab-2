# Лабораторная работа №2 (Кашапов А.И., гр. 6231)

## Инференс и обучение НС

В рамках данной лабораторной работы были построены два пайплайна:

1. Который позволяет получить предсказания для исходных данных с помощью некоторой модели.
2. Который позволяет обучить или дообучить целевую модель.

Для построения такого пайплайна использовался Apache Airflow.

## Пайплайн для инференса данных

Построенный пайплайн выполняет следующие действия поочередно:

1. Производи мониторинг целевой папки на предмет появления новых видеофайлов.
2. Извлекает аудиодорожку из исходного видеофайла.
3. Преобразовывает аудиодорожку в текст с помощью нейросетевой модели.
4. Формирует конспект на основе полученного текста.
5. Формирует выходной .pdf файл с конспектом.

Разработанный DAG:

```
from datetime import datetime

from airflow import DAG
from airflow.providers.docker.operators.docker import DockerOperator
from airflow.sensors.filesystem import FileSensor
from docker.types import Mount


_PATH = '/opt/airflow/data'

default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
    'retries': 1,
}

dag = DAG(
    dag_id='audio-to-text-to-summary-to-pdf',
    default_args=default_args,
    description='DAG for extracting audio, transforming to text, summarizing, and saving as PDF',
    schedule_interval=None,
)

wait_for_new_file = FileSensor(
    task_id='wait_for_new_file',
    poke_interval=10,
    filepath=_PATH,
    fs_conn_id='filesensor',
    dag=dag,
)

extract_audio = DockerOperator(
    task_id='extract_audio',
    image='jrottenberg/ffmpeg',
    command='-i /data/input.mp4 -vn -acodec copy /data/my_audio.aac',
    mounts=[Mount(source='/data', target='/data', type='bind')],
    docker_url="tcp://docker-proxy:2375",
    dag=dag,
)

transform_audio_to_text = DockerOperator(
    task_id='transform_audio_to_text',
    image='test_transformers_image:latest',
    command='python /data/get_text.py',
    mounts=[Mount(source='/data', target='/data', type='bind')],
    docker_url="tcp://docker-proxy:2375",
    dag=dag,
)

summarize_text = DockerOperator(
    task_id='summarize_text',
    image='test_transformers_image:latest',
    command='python /data/get_summary.py',
    mounts=[Mount(source='/data', target='/data', type='bind')],
    docker_url="tcp://docker-proxy:2375",
    dag=dag,
)

save_to_pdf = DockerOperator(
    task_id='save_to_pdf',
    image='test_transformers_image:latest',
    command='python /data/get_pdf.py',
    mounts=[Mount(source='/data', target='/data', type='bind')],
    docker_url="tcp://docker-proxy:2375",
    dag=dag,
)

wait_for_new_file >> extract_audio >> transform_audio_to_text >> summarize_text >> save_to_pdf

```

Дополнительно был развернут Docker-контейнер с нужными зависимостями. Описывается Docker-файлом:

```
FROM python:3.8

RUN pip install --upgrade pip

RUN pip install torch transformers reportlab

WORKDIR /app
```

Для шагов 3-5 Pipeline был написан исполняемый Python-скрипт;

3. Шаг с ID задачи: 'transform_audio_to_text' `get_text.py`;
4. Шаг с ID задачи: 'summarize_text' `get_summary.py`;
5. Шаг с ID задачи: 'save_to_pdf' `get_pdf.py`;

В качестве "движка" я использовал библиотеку [`transformers`](https://github.com/huggingface/transformers);

Видеоролик, который я использовал для обработки, доступен в YouTube: https://www.youtube.com/watch?v=dd1kN_myNDs

Получившийся в итоге файл `output.pdf` содержит результат работы построенного Pipeline.

## Пайплайн для обучения модели

Поскольку моя научная работа не связана с машинными обучением, для выполнения задачи я выбрал набор данных с информацией о ценах на недвижимость в пригородах Бостона: `boston_housing`;

Построенный пайплайн будет выполнять следующие действия:

1. Читать набор файлов.
2. Формировать пакет данных для обучения модели + делать небольшую предобработку.
3. Обучать модель.
4. Сохранять данные результатов обученя (логи, значения функции ошибки) в текстовый файл.

Разработанный DAG:

```
from datetime import datetime

from airflow import DAG
from airflow.providers.docker.operators.docker import DockerOperator
from docker.types import Mount

default_args = {
    'owner': 'airflow',
    'start_date': datetime(2023, 1, 1),
    'retries': 1,
}

dag = DAG(
    dag_id='data-engineering-lab-2-2',
    default_args=default_args,
    description='DAG for data engineering lab 2: training a neural network',
    schedule_interval=None,
)

read_data = DockerOperator(
    task_id='read_data',
    image='my_tf_image:latest',
    command='python /data/make_data.py',
    mounts=[Mount(source='/data', target='/data', type='bind')],
    docker_url="tcp://docker-proxy:2375",
    dag=dag,
)

train = DockerOperator(
    task_id='train_model',
    image='my_tf_image:latest',
    command='python /data/train.py',
    mounts=[Mount(source='/data', target='/data', type='bind')],
    docker_url="tcp://docker-proxy:2375",
    dag=dag,
)

read_data >> train
```

Стоит отметить, что здесь я использовал другой контейнер:

```
FROM tensorflow/tensorflow:latest

RUN pip install pandas

WORKDIR /app
```

Шаги в данном Pipeline, на мой взгляд, проще по сравнению с предыдущим.

Для логгирования я использовал build-in библиотеку `logging`. Прцесс обучения зафиксирован в текстовом файле `training_logs.txt`: вот небольшой кусок из него:

```
2023-12-03 01:18:50,145 - INFO - Epoch 1/100 - loss: 544.9515 - mae: 21.5042 - val_loss: 596.4896 - val_mae: 22.6560
2023-12-03 01:18:50,200 - INFO - Epoch 2/100 - loss: 510.9792 - mae: 20.7317 - val_loss: 562.0468 - val_mae: 21.8810
2023-12-03 01:18:50,257 - INFO - Epoch 3/100 - loss: 475.6271 - mae: 19.8868 - val_loss: 524.2816 - val_mae: 20.9962
2023-12-03 01:18:50,314 - INFO - Epoch 4/100 - loss: 437.6606 - mae: 18.9385 - val_loss: 483.4026 - val_mae: 19.9983
2023-12-03 01:18:50,381 - INFO - Epoch 5/100 - loss: 396.0114 - mae: 17.8619 - val_loss: 437.7119 - val_mae: 18.8374
2023-12-03 01:18:50,441 - INFO - Epoch 6/100 - loss: 350.5229 - mae: 16.6248 - val_loss: 390.0493 - val_mae: 17.5647
2023-12-03 01:18:50,495 - INFO - Epoch 7/100 - loss: 304.3200 - mae: 15.2797 - val_loss: 341.4105 - val_mae: 16.1631
2023-12-03 01:18:50,549 - INFO - Epoch 8/100 - loss: 259.2653 - mae: 13.9307 - val_loss: 295.3253 - val_mae: 14.7005
2023-12-03 01:18:50,601 - INFO - Epoch 9/100 - loss: 218.3945 - mae: 12.5480 - val_loss: 251.6648 - val_mae: 13.1729
...
```